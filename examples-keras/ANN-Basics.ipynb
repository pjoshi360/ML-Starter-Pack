{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:/Users/R AMARTYA/Desktop/Artificial_Neural_Networks/Churn_Modelling.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = dataset.iloc[:, 3:13].values\n",
    "train_target = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ..., \n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The LabelEncoder is a way to encode class levels.\n",
    "train = [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"]\n",
    "test = [\"tokyo\", \"tokyo\", \"paris\"]\n",
    "le.fit(train).transform(test)\n",
    "Output: array([2, 2, 1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before OneHotEncoder\n",
    "\n",
    "f0 f1 f2\n",
    "0, 0, 3\n",
    "1, 1, 0\n",
    "0, 2, 1\n",
    "1, 0, 2\n",
    "\n",
    "After OneHotEncoding\n",
    "\n",
    "|f0|  |  f1 |  |   f2   |\n",
    "\n",
    "1, 0, 1, 0, 0, 0, 0, 0, 1 \n",
    "0, 1, 0, 1, 0, 1, 0, 0, 0\n",
    "1, 0, 0, 0, 1, 0, 1, 0, 0\n",
    "0, 1, 1, 0, 0, 0, 0, 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features[:,1]=le.fit_transform(train_features[:,1])\n",
    "train_features[:,2]=le.fit_transform(train_features[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ..., \n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot-Encoding has a the advantage that the result is binary rather than ordinal and that everything sits in an orthogonal vector space. The disadvantage is that for high cardinality, the feature space can really blow up quickly and you start fighting with the curse of dimensionality. In these cases, typically employ one-hot-encoding followed by PCA for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between OneHotEncoding and DictVectorizer:\n",
    "DictVectorizer does not work with categorical columns with int type values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oe = OneHotEncoder(categorical_features = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features=oe.fit_transform(train_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features=train_features[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   6.19000000e+02, ...,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.01348880e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.08000000e+02, ...,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.12542580e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   5.02000000e+02, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.13931570e+05],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.09000000e+02, ...,\n",
       "          0.00000000e+00,   1.00000000e+00,   4.20855800e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   7.72000000e+02, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   9.28885200e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.92000000e+02, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   3.81907800e+04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_features, train_target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_x = sc.fit_transform(train_x)\n",
    "test_x = sc.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this code and check the accuracy in case of Naive Bayes or Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#clf = GaussianNB()\n",
    "#clf = clf.fit(train_x, train_y)\n",
    "#predict_y = clf.predict(test_x)\n",
    "#print (\"Naive Bayes Acuracy = %.2f\" % (accuracy_score(test_y, predict_y)))\n",
    "#cm = confusion_matrix(test_y, predict_y)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#RandomForest = RandomForestClassifier(n_estimators=1000)\n",
    "#RandomForest.fit(train_x,train_y)\n",
    "#predict_y = RandomForest.predict(test_x)\n",
    "#print (\"RandomForest Accuracy = %.2f\" % (accuracy_score(test_y, predict_y)))\n",
    "#cm = confusion_matrix(test_y, predict_y)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models in Keras are defined as a sequence of layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Sequential model and add layers one at a time until we are happy with our network topology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to get right is to ensure the input layer has the right number of inputs. This can be specified when creating the first layer with the input_dim argument and setting it to 11 for the 11 input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this case, we initialize the network weights to a small random number generated from a uniform distribution (‘uniform‘), in this case between 0 and 0.05 because that is the default uniform weight initialization in Keras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the number of neurons in the layer as the first argument, the initialization method as the second argument as init and specify the activation function using the activation argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the rectifier (‘relu‘) activation function on the first two layers and the sigmoid function in the output layer.We use a sigmoid on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R AMARTYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\R AMARTYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\R AMARTYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "clf = Sequential()\n",
    "clf.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "clf.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "clf.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model uses the efficient numerical libraries under the covers (the so-called backend) such as Theano or TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must specify the loss function to use to evaluate a set of weights, the optimizer used to search through different weights for the network and any optional metrics we would like to collect and report during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will use logarithmic loss, which for a binary classification problem is defined in Keras as “binary_crossentropy“. We will also use the efficient gradient descent algorithm “adam” for no other reason that it is an efficient default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, because it is a classification problem, we will collect and report the classification accuracy as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train or fit our model on our loaded data by calling the fit() function on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process will run for a fixed number of iterations through the dataset called epochs, that we must specify using the nepochs argument. We can also set the number of instances that are evaluated before a weight update in the network is performed, called the batch size and set using the batch_size argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size: Number of samples per gradient update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R AMARTYA\\Anaconda3\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.4916 - acc: 0.7961\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.4304 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.4271 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4218 - acc: 0.8141\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4154 - acc: 0.8264\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4108 - acc: 0.8321\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4076 - acc: 0.8344\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4051 - acc: 0.8359\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4034 - acc: 0.8344\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.4021 - acc: 0.8336\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4015 - acc: 0.8357\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.4003 - acc: 0.8362\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3997 - acc: 0.8355\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3994 - acc: 0.8331\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3984 - acc: 0.8346\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3982 - acc: 0.8354\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3976 - acc: 0.8339\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3973 - acc: 0.8342\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3968 - acc: 0.8340\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3972 - acc: 0.8352\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3965 - acc: 0.8351\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3956 - acc: 0.8350\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3959 - acc: 0.8342\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3952 - acc: 0.8372\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3956 - acc: 0.8359\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3956 - acc: 0.8336\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3948 - acc: 0.8340\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3951 - acc: 0.8344\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3947 - acc: 0.8359\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3948 - acc: 0.8345\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3944 - acc: 0.8352\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3946 - acc: 0.8362\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3938 - acc: 0.8356\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3941 - acc: 0.8366\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3941 - acc: 0.8366\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3943 - acc: 0.8367\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3945 - acc: 0.8357\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3939 - acc: 0.8340\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3943 - acc: 0.8356\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3939 - acc: 0.8364\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3931 - acc: 0.8377\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3942 - acc: 0.8369\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3936 - acc: 0.8361\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3940 - acc: 0.8352\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3945 - acc: 0.8365\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3940 - acc: 0.8361\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3939 - acc: 0.8356\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3935 - acc: 0.8355\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3933 - acc: 0.8349\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3940 - acc: 0.8352\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3939 - acc: 0.8354\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3939 - acc: 0.8366\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3936 - acc: 0.8351\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3933 - acc: 0.8356\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3940 - acc: 0.8352: 0s - loss: 0.3947 - ac\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3938 - acc: 0.8362\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3933 - acc: 0.8372\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3932 - acc: 0.8367\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3930 - acc: 0.8382\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3931 - acc: 0.8357\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3936 - acc: 0.8362\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3926 - acc: 0.8371\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3937 - acc: 0.8365\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3933 - acc: 0.8360\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3932 - acc: 0.8357\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3939 - acc: 0.8361\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3932 - acc: 0.8351\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3932 - acc: 0.8351\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3932 - acc: 0.8380\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3931 - acc: 0.8359\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3936 - acc: 0.8367\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3935 - acc: 0.8362\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3931 - acc: 0.8364\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3933 - acc: 0.8364\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 12s 1ms/step - loss: 0.3932 - acc: 0.8367\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3933 - acc: 0.8350\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3927 - acc: 0.8372\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3928 - acc: 0.8362\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 17s 2ms/step - loss: 0.3926 - acc: 0.8359\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3931 - acc: 0.8377\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 15s 2ms/step - loss: 0.3932 - acc: 0.8376\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3932 - acc: 0.8357\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3924 - acc: 0.8377\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3919 - acc: 0.8361\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3922 - acc: 0.8379\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 12s 2ms/step - loss: 0.3922 - acc: 0.8377\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3920 - acc: 0.8375\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.3921 - acc: 0.8374\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3910 - acc: 0.8401\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3902 - acc: 0.8386\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3894 - acc: 0.8400\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3880 - acc: 0.8386\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3863 - acc: 0.8387\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3829 - acc: 0.8367\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3805 - acc: 0.8377\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3767 - acc: 0.8380\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3742 - acc: 0.8385\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3710 - acc: 0.8437\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3681 - acc: 0.8439\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.3660 - acc: 0.8469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280c96de278>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x, train_y, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy = 0.85\n",
      "[[1519   76]\n",
      " [ 232  173]]\n"
     ]
    }
   ],
   "source": [
    "predict_y = clf.predict(test_x)\n",
    "predict_y = (predict_y > 0.5)\n",
    "print (\" Accuracy = %.2f\" % (accuracy_score(test_y, predict_y)))\n",
    "cm = confusion_matrix(test_y, predict_y)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.718500889281\n",
      "0.781141699866\n",
      "0.689755795503\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_y, predict_y, average=\"macro\"))\n",
    "print(precision_score(test_y, predict_y, average=\"macro\"))\n",
    "print(recall_score(test_y, predict_y, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
